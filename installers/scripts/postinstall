#!/bin/bash

# TypeMagic Ollama Installer for macOS
# Post-install script running as root (from .pkg installer)

LOG_FILE="/tmp/typemagic_ollama_install.log"
OLLAMA_ORIGIN="chrome-extension://*"
MAX_WAIT=30

log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') $1" | tee -a "$LOG_FILE"
}

log "Starting TypeMagic Ollama Setup (Post-install)..."

# Detect the real user (the one currently logged into the console)
CONSOLE_USER=$(stat -f "%Su" /dev/console 2>/dev/null)

if [ -z "$CONSOLE_USER" ] || [ "$CONSOLE_USER" = "root" ]; then
    # Fallback: try to find a non-root user from /Users
    CONSOLE_USER=$(ls /Users | grep -v Shared | grep -v Guest | head -1)
    if [ -z "$CONSOLE_USER" ]; then
        log "Warning: No console user found. Installing as root."
        TARGET_USER="root"
        USER_HOME="/var/root"
    else
        TARGET_USER="$CONSOLE_USER"
        USER_HOME="/Users/$TARGET_USER"
    fi
else
    TARGET_USER="$CONSOLE_USER"
    USER_HOME=$(dscl . -read /Users/$TARGET_USER NFSHomeDirectory 2>/dev/null | awk '{print $2}')
    if [ -z "$USER_HOME" ]; then
        USER_HOME="/Users/$TARGET_USER"
    fi
fi

log "Target User: $TARGET_USER"
log "User Home: $USER_HOME"

# 1. Detect/Install Ollama (System-wide)
if ! command -v ollama &> /dev/null; then
    log "Ollama not found. Installing..."
    if curl -fsSL https://ollama.com/install.sh | sh; then
        log "Ollama installed successfully."
    else
        log "ERROR: Failed to install Ollama."
        exit 1
    fi
else
    log "Ollama is already installed."
fi

# 2. Set Environment Variable for the USER
log "Configuring environment variables..."

# Create .zshrc if it doesn't exist (macOS default shell)
ZSHRC="$USER_HOME/.zshrc"
if [ ! -f "$ZSHRC" ]; then
    touch "$ZSHRC"
    chown "$TARGET_USER" "$ZSHRC"
fi

if ! grep -q "OLLAMA_ORIGINS" "$ZSHRC" 2>/dev/null; then
    echo "export OLLAMA_ORIGINS=\"$OLLAMA_ORIGIN\"" >> "$ZSHRC"
    chown "$TARGET_USER" "$ZSHRC"
    log "Added OLLAMA_ORIGINS to $ZSHRC"
else
    log "OLLAMA_ORIGINS already configured in $ZSHRC"
fi

# Also add to .bash_profile if it exists
BASH_PROFILE="$USER_HOME/.bash_profile"
if [ -f "$BASH_PROFILE" ]; then
    if ! grep -q "OLLAMA_ORIGINS" "$BASH_PROFILE" 2>/dev/null; then
        echo "export OLLAMA_ORIGINS=\"$OLLAMA_ORIGIN\"" >> "$BASH_PROFILE"
        chown "$TARGET_USER" "$BASH_PROFILE"
        log "Added OLLAMA_ORIGINS to $BASH_PROFILE"
    fi
fi

# 3. Stop any existing Ollama server
log "Stopping any existing Ollama server..."
pkill -9 ollama 2>/dev/null || true
sleep 2

# 4. Start Ollama server as user with OLLAMA_ORIGINS set
log "Starting Ollama server as $TARGET_USER with CORS enabled..."

# Use launchctl to properly start the process as the user
# This ensures the process survives after the script exits
if [ "$TARGET_USER" != "root" ]; then
    USER_UID=$(id -u "$TARGET_USER")
    launchctl asuser "$USER_UID" sudo -u "$TARGET_USER" sh -c "OLLAMA_ORIGINS='$OLLAMA_ORIGIN' ollama serve > /tmp/ollama_serve.log 2>&1 &"
else
    OLLAMA_ORIGINS="$OLLAMA_ORIGIN" ollama serve > /tmp/ollama_serve.log 2>&1 &
fi

# Wait for server to be ready (with timeout)
log "Waiting for Ollama server to start..."
for i in $(seq 1 $MAX_WAIT); do
    if curl -s http://127.0.0.1:11434/api/version > /dev/null 2>&1; then
        log "Ollama server is ready."
        break
    fi
    if [ $i -eq $MAX_WAIT ]; then
        log "ERROR: Ollama server failed to start within ${MAX_WAIT}s. Check /tmp/ollama_serve.log"
        exit 1
    fi
    sleep 1
done

# 5. Pull Model as USER
log "Pulling llama3.1:8b model (this may take several minutes)..."
if [ "$TARGET_USER" != "root" ]; then
    if sudo -u "$TARGET_USER" ollama pull llama3.1:8b; then
        log "Model downloaded successfully."
    else
        log "ERROR: Failed to download model."
        exit 1
    fi
else
    if ollama pull llama3.1:8b; then
        log "Model downloaded successfully."
    else
        log "ERROR: Failed to download model."
        exit 1
    fi
fi

log "============================================"
log "Setup Complete!"
log "Ollama is running with CORS enabled for Chrome extensions."
log "You can now use TypeMagic with Ollama as your AI provider."
log "============================================"

exit 0